---
title: "class07 machine learning"
author: "amy (pid A16962111)"
format: pdf
editor: visual
---

# clustering methods

The broad goal here is to find groupings (clusters) in your input data.

## kmeans

First, let's make up some data to cluster. Make a vector of length 60 with 30 points centered on -3 and 30 points at +3.

```{r}
tmp <- c(rnorm(30, mean=-3), rnorm(30, mean=3))
```

I will now make a x,y dataset with 2 groups of points.

```{r}
x <- cbind(x=tmp, y=rev(tmp))
plot(x)
```

```{r}
k <- kmeans(x, centers=2)
k
```

> Q. From your result object `k` how many points are in each cluster?

```{r}
k$size
```

> Q. What "component" of your result object details the cluster membership?

```{r}
k$cluster
```

> Q. Cluster centers?

```{r}
k$centers
```

> Q. Plot of our clustering results

```{r}
plot(x, col=k$cluster)
points(k$centers, col="blue", pch=15, cex=2)
```

We can cluster into 4 grps:

```{r}
k2 <- kmeans(x, centers=4)
plot(x, col=k2$cluster)
```

A big limitation of kmeans is that it does what you ask even if you ask for silly clusters.

## hierarchical clustering

The main base R function for hierarchical clustering is `hclust()` . Unlike `kmeans()`, you can not just pass it your data as input. You first need to calculate a distance matrix.

```{r}
d <- dist(x)
hc <- hclust(d)
plot(hc)
abline(h=10, col="red")
```

To make the "cut" and get our cluster membership vector, we can use the `cutree()` function.

```{r}
grps <- cutree(hc, h=10)
grps
plot(x, col=grps)
```

# Principal Component Analysis (PCA)

Here we will do PCA of UK food data:

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url, row.names=1)
#View(x)
```

> **Q1**. How many rows and columns are in your new data frame named `x`? What R functions could you use to answer this questions?

```{r}
nrow(x)
ncol(x)
```

```{r}
head(x)
```

> **Q2.** Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

```{r}
#rownames(x) <- x[,1]
#x <- x[,-1]
#head(x)
```

I prefer `row.names=1` , since running the code above more than once would continue to remove columns of data.

> **Q3**: Changing what optional argument in the above **barplot()** function results in the following plot?

Changing `beside=T` to `beside=F`.

```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))

```

> **Q5**: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

If a point lies on the diagonal, it indicates that value is similar to the other observations for that variable.

```{r}
pairs(x, col=rainbow(10), pch=16)
#?pairs
```

> **Q6**. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

It looks like the blue and orange points are different between N. Ireland and the other countries of the UK.

## PCA to the rescue

The main "base" R function for PCA is called `prcomp()`. Here we need to take the transpose of our input, as we want the countries in the rows and the food as the columns.

```{r}
pca <- prcomp(t(x))
summary(pca)
```

> Q. How much variance is captured in 2 PCs?

96.5%

> **Q7**. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

To make our main "PC score plot" or "PC1 vs PC2 plot" or "PC plot" or "ordination plot":

```{r}
attributes(pca)
```

We are after the `pca$x` result component to make our main PCA plot.

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1, (67.4%)", ylab="PC2 (29%)", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```

**Q8.** Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
mycols <- c("orange", "red", "blue", "darkgreen")
plot(pca$x[,1], pca$x[,2], xlab="PC1, (67.4%)", ylab="PC2 (29%)", xlim=c(-270,500),
     col=mycols, pch=16)
text(pca$x[,1], pca$x[,2], colnames(x))
```

Another important result from PCA is how the original variables (in this case, the foods) contribute to the PCs.

This is contained in the `pca$rotation` object - folks often call this the "loadings" or "contributions" to the PCs.

```{r}
pca$rotation
```

We can make a plot along PC1.

```{r}
library(ggplot2)
contrib <- as.data.frame(pca$rotation)
ggplot(contrib) +
  aes(PC1, rownames(contrib)) +
  geom_col()
```
